{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"0178a299058a4610a3b845f1ae875ac1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce24cd856647498eaa93b8b981ab0fbd","max":546517,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dec340546de549a58782d120fa8d536a","value":546517}},"13e2f4461f2c4701b292bd102b2cbeb1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e4e77f1e00e478eb66f60a19d32fb66","placeholder":"​","style":"IPY_MODEL_8e84f2ea84d941a4b94edd728a7b89fc","value":"vocab.txt: 100%"}},"1faffb0a2ab849d191efb6b65b0ea102":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_42bae3bf886c4999ad9a20b8164e6159","placeholder":"​","style":"IPY_MODEL_fecc4b5e32d14f0499c181abe2e1641c","value":"config.json: 100%"}},"2ae66e2fbba241499f03ad2bd4828af8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"388e0307ac974c6787c55ab0e7a22fb0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4011a9b2fa5a4bd9873c48891361e5e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1faffb0a2ab849d191efb6b65b0ea102","IPY_MODEL_d88f48de82934ed7a4564ebeb2e870b1","IPY_MODEL_fd729c3ba94e4327a12ab8d2e3de63ed"],"layout":"IPY_MODEL_388e0307ac974c6787c55ab0e7a22fb0"}},"42bae3bf886c4999ad9a20b8164e6159":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"493c7173aaa049139cda553df4fcbfea":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e4e77f1e00e478eb66f60a19d32fb66":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e70245367734976b684c92bf39afe94":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_13e2f4461f2c4701b292bd102b2cbeb1","IPY_MODEL_0178a299058a4610a3b845f1ae875ac1","IPY_MODEL_c1e0a084b9564d33b9d29d159c29bd41"],"layout":"IPY_MODEL_82789f34d99c4bf3bca16496c14f7331"}},"74e38d925c2c43ef8327ad85ac0fcee3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82789f34d99c4bf3bca16496c14f7331":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e84f2ea84d941a4b94edd728a7b89fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f972664f79a4d5a8f95d55d241f03e4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b59570a3cfeb449db04045a31b1654e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be9bc652b0bd40d5be8f9447aa013728":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1e0a084b9564d33b9d29d159c29bd41":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f972664f79a4d5a8f95d55d241f03e4","placeholder":"​","style":"IPY_MODEL_74e38d925c2c43ef8327ad85ac0fcee3","value":" 547k/547k [00:00&lt;00:00, 13.9MB/s]"}},"ce24cd856647498eaa93b8b981ab0fbd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d88f48de82934ed7a4564ebeb2e870b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ae66e2fbba241499f03ad2bd4828af8","max":652,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b59570a3cfeb449db04045a31b1654e9","value":652}},"dec340546de549a58782d120fa8d536a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fd729c3ba94e4327a12ab8d2e3de63ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_493c7173aaa049139cda553df4fcbfea","placeholder":"​","style":"IPY_MODEL_be9bc652b0bd40d5be8f9447aa013728","value":" 652/652 [00:00&lt;00:00, 15.2kB/s]"}},"fecc4b5e32d14f0499c181abe2e1641c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10291299,"sourceType":"datasetVersion","datasetId":6369155},{"sourceId":10311825,"sourceType":"datasetVersion","datasetId":6383565},{"sourceId":10312117,"sourceType":"datasetVersion","datasetId":6383763},{"sourceId":10319892,"sourceType":"datasetVersion","datasetId":6389325},{"sourceId":10319954,"sourceType":"datasetVersion","datasetId":6389368}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers torch pandas scikit-learn\n","metadata":{"id":"7JKlB2Nypo00","trusted":true,"execution":{"iopub.status.busy":"2024-12-31T05:09:25.163230Z","iopub.execute_input":"2024-12-31T05:09:25.163532Z","iopub.status.idle":"2024-12-31T05:09:29.832473Z","shell.execute_reply.started":"2024-12-31T05:09:25.163507Z","shell.execute_reply":"2024-12-31T05:09:29.831502Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# import os\n# import shutil\n# # shutil.rmtree('./state.db')\n# os.remove('./state.db')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T05:09:29.833224Z","iopub.execute_input":"2024-12-31T05:09:29.833489Z","iopub.status.idle":"2024-12-31T05:09:29.837102Z","shell.execute_reply.started":"2024-12-31T05:09:29.833463Z","shell.execute_reply":"2024-12-31T05:09:29.836365Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# previous","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AutoTokenizer\n\nfile_path = \"/kaggle/input/to-add-dataset/final_final.xlsx\"\np_data = pd.read_excel(file_path)\np_data=p_data[['Questions','Reference Answer',\"Student's Answer\",\"Similarity\"]]\n\ndef encode(x):\n    label={\n        'low':0,\n        'medium':1,\n        'high':2\n    }\n    x=x.lower().strip()\n    return label[x]\np_data['Similarity']=p_data['Similarity'].apply(encode)\np_data.columns=['Questions','Reference Answer','Student\\'s Answer','Obtained marks']\np_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T05:09:29.837975Z","iopub.execute_input":"2024-12-31T05:09:29.838167Z","iopub.status.idle":"2024-12-31T05:09:37.186824Z","shell.execute_reply.started":"2024-12-31T05:09:29.838151Z","shell.execute_reply":"2024-12-31T05:09:37.185984Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                           Questions  \\\n0  पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...   \n1  पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...   \n2  पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...   \n3  पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...   \n4  पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...   \n\n                                    Reference Answer  \\\n0  पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...   \n1  पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...   \n2  पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...   \n3  पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...   \n4  पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...   \n\n                                    Student's Answer  Obtained marks  \n0  पढाईले मानिसलाई केवल केही ज्ञान मात्र जीवनमा त...               0  \n1  ढाईले तर केही थाहा दिने गर्,छद जसले जीवनमा मद्...               1  \n2  पढाई मानिसको सोच र ावीीजनमैशल ठूलो परिवर्तन ल्...               2  \n3  पढाई केवल रप््पायत स्रोत हो, तर जीवनका समस्याह...               0  \n4  पढाईले जीवनका केही पक्षहरूमा परिवर्तन ल्याउँछ।...               1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Questions</th>\n      <th>Reference Answer</th>\n      <th>Student's Answer</th>\n      <th>Obtained marks</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...</td>\n      <td>पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...</td>\n      <td>पढाईले मानिसलाई केवल केही ज्ञान मात्र जीवनमा त...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...</td>\n      <td>पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...</td>\n      <td>ढाईले तर केही थाहा दिने गर्,छद जसले जीवनमा मद्...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...</td>\n      <td>पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...</td>\n      <td>पढाई मानिसको सोच र ावीीजनमैशल ठूलो परिवर्तन ल्...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...</td>\n      <td>पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...</td>\n      <td>पढाई केवल रप््पायत स्रोत हो, तर जीवनका समस्याह...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...</td>\n      <td>पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...</td>\n      <td>पढाईले जीवनका केही पक्षहरूमा परिवर्तन ल्याउँछ।...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"p_data=p_data.iloc[int(p_data.shape[0]/2):,:]\np_data.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T05:09:37.187645Z","iopub.execute_input":"2024-12-31T05:09:37.188122Z","iopub.status.idle":"2024-12-31T05:09:37.194119Z","shell.execute_reply.started":"2024-12-31T05:09:37.188095Z","shell.execute_reply":"2024-12-31T05:09:37.193367Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(6031, 4)"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"# arabic","metadata":{}},{"cell_type":"code","source":"\nfile_path = \"/kaggle/input/arabic/to_process_arabic.xlsx\"\na_data = pd.read_excel(file_path)\na_data=a_data.loc[:,['Question_E','Reference Answer_E','Student\\'s Answer_E','Obtained marks']]\na_data.columns=['Questions','Reference Answer','Student\\'s Answer','Obtained marks']\na_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T05:09:37.195088Z","iopub.execute_input":"2024-12-31T05:09:37.195416Z","iopub.status.idle":"2024-12-31T05:09:37.644628Z","shell.execute_reply.started":"2024-12-31T05:09:37.195392Z","shell.execute_reply":"2024-12-31T05:09:37.643840Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                             Questions  \\\n0  साइबर अपराध शब्द परिभाषित गर्नुहोस्   \n1  साइबर अपराध शब्द परिभाषित गर्नुहोस्   \n2  साइबर अपराध शब्द परिभाषित गर्नुहोस्   \n3  साइबर अपराध शब्द परिभाषित गर्नुहोस्   \n4  साइबर अपराध शब्द परिभाषित गर्नुहोस्   \n\n                                    Reference Answer  \\\n0  यो सबै गैरकानूनी व्यवहार हो जुन इलेक्ट्रोनिक उ...   \n1  यो सबै गैरकानूनी व्यवहार हो जुन इलेक्ट्रोनिक उ...   \n2  यो सबै गैरकानूनी व्यवहार हो जुन इलेक्ट्रोनिक उ...   \n3  यो सबै गैरकानूनी व्यवहार हो जुन इलेक्ट्रोनिक उ...   \n4  यो सबै गैरकानूनी व्यवहार हो जुन इलेक्ट्रोनिक उ...   \n\n                                    Student's Answer  Obtained marks  \n0  यो सबै गैरकानूनी व्यवहार हो जुन इलेक्ट्रोनिक उ...           100.0  \n1  आर्थिक प्रतिफल प्राप्त गर्ने र पीडितलाई हानि प...            60.0  \n2  यो सबै इलेक्ट्रोनिक यन्त्रहरू द्वारा गरिएको अन...           100.0  \n3  पीडितलाई भौतिक वा नैतिक हानि पुर्‍याउन इलेक्ट्...            52.5  \n4  यो गैरकानूनी व्यवहार हो जसले इलेक्ट्रोनिक माध्...            80.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Questions</th>\n      <th>Reference Answer</th>\n      <th>Student's Answer</th>\n      <th>Obtained marks</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>साइबर अपराध शब्द परिभाषित गर्नुहोस्</td>\n      <td>यो सबै गैरकानूनी व्यवहार हो जुन इलेक्ट्रोनिक उ...</td>\n      <td>यो सबै गैरकानूनी व्यवहार हो जुन इलेक्ट्रोनिक उ...</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>साइबर अपराध शब्द परिभाषित गर्नुहोस्</td>\n      <td>यो सबै गैरकानूनी व्यवहार हो जुन इलेक्ट्रोनिक उ...</td>\n      <td>आर्थिक प्रतिफल प्राप्त गर्ने र पीडितलाई हानि प...</td>\n      <td>60.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>साइबर अपराध शब्द परिभाषित गर्नुहोस्</td>\n      <td>यो सबै गैरकानूनी व्यवहार हो जुन इलेक्ट्रोनिक उ...</td>\n      <td>यो सबै इलेक्ट्रोनिक यन्त्रहरू द्वारा गरिएको अन...</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>साइबर अपराध शब्द परिभाषित गर्नुहोस्</td>\n      <td>यो सबै गैरकानूनी व्यवहार हो जुन इलेक्ट्रोनिक उ...</td>\n      <td>पीडितलाई भौतिक वा नैतिक हानि पुर्‍याउन इलेक्ट्...</td>\n      <td>52.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>साइबर अपराध शब्द परिभाषित गर्नुहोस्</td>\n      <td>यो सबै गैरकानूनी व्यवहार हो जुन इलेक्ट्रोनिक उ...</td>\n      <td>यो गैरकानूनी व्यवहार हो जसले इलेक्ट्रोनिक माध्...</td>\n      <td>80.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"def change_label(x):\n    x=x/50\n    if (x<=0.5):\n        x=0\n    elif (x>0.5 and x<=1.5):\n        x=1\n    elif (x>1.5 and x<=2 ):\n        x=2\n    return x\nchange_label(1.28)\na_data['Obtained marks']=a_data['Obtained marks'].apply(change_label)\na_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T05:09:37.646636Z","iopub.execute_input":"2024-12-31T05:09:37.646861Z","iopub.status.idle":"2024-12-31T05:09:37.657581Z","shell.execute_reply.started":"2024-12-31T05:09:37.646842Z","shell.execute_reply":"2024-12-31T05:09:37.656651Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                             Questions  \\\n0  साइबर अपराध शब्द परिभाषित गर्नुहोस्   \n1  साइबर अपराध शब्द परिभाषित गर्नुहोस्   \n2  साइबर अपराध शब्द परिभाषित गर्नुहोस्   \n3  साइबर अपराध शब्द परिभाषित गर्नुहोस्   \n4  साइबर अपराध शब्द परिभाषित गर्नुहोस्   \n\n                                    Reference Answer  \\\n0  यो सबै गैरकानूनी व्यवहार हो जुन इलेक्ट्रोनिक उ...   \n1  यो सबै गैरकानूनी व्यवहार हो जुन इलेक्ट्रोनिक उ...   \n2  यो सबै गैरकानूनी व्यवहार हो जुन इलेक्ट्रोनिक उ...   \n3  यो सबै गैरकानूनी व्यवहार हो जुन इलेक्ट्रोनिक उ...   \n4  यो सबै गैरकानूनी व्यवहार हो जुन इलेक्ट्रोनिक उ...   \n\n                                    Student's Answer  Obtained marks  \n0  यो सबै गैरकानूनी व्यवहार हो जुन इलेक्ट्रोनिक उ...               2  \n1  आर्थिक प्रतिफल प्राप्त गर्ने र पीडितलाई हानि प...               1  \n2  यो सबै इलेक्ट्रोनिक यन्त्रहरू द्वारा गरिएको अन...               2  \n3  पीडितलाई भौतिक वा नैतिक हानि पुर्‍याउन इलेक्ट्...               1  \n4  यो गैरकानूनी व्यवहार हो जसले इलेक्ट्रोनिक माध्...               2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Questions</th>\n      <th>Reference Answer</th>\n      <th>Student's Answer</th>\n      <th>Obtained marks</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>साइबर अपराध शब्द परिभाषित गर्नुहोस्</td>\n      <td>यो सबै गैरकानूनी व्यवहार हो जुन इलेक्ट्रोनिक उ...</td>\n      <td>यो सबै गैरकानूनी व्यवहार हो जुन इलेक्ट्रोनिक उ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>साइबर अपराध शब्द परिभाषित गर्नुहोस्</td>\n      <td>यो सबै गैरकानूनी व्यवहार हो जुन इलेक्ट्रोनिक उ...</td>\n      <td>आर्थिक प्रतिफल प्राप्त गर्ने र पीडितलाई हानि प...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>साइबर अपराध शब्द परिभाषित गर्नुहोस्</td>\n      <td>यो सबै गैरकानूनी व्यवहार हो जुन इलेक्ट्रोनिक उ...</td>\n      <td>यो सबै इलेक्ट्रोनिक यन्त्रहरू द्वारा गरिएको अन...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>साइबर अपराध शब्द परिभाषित गर्नुहोस्</td>\n      <td>यो सबै गैरकानूनी व्यवहार हो जुन इलेक्ट्रोनिक उ...</td>\n      <td>पीडितलाई भौतिक वा नैतिक हानि पुर्‍याउन इलेक्ट्...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>साइबर अपराध शब्द परिभाषित गर्नुहोस्</td>\n      <td>यो सबै गैरकानूनी व्यवहार हो जुन इलेक्ट्रोनिक उ...</td>\n      <td>यो गैरकानूनी व्यवहार हो जसले इलेक्ट्रोनिक माध्...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"# our data","metadata":{}},{"cell_type":"code","source":"\n\nfile_path = \"/kaggle/input/our-data/final 4.xlsx\"\no_data = pd.read_excel(file_path)\no_data.columns=['Questions','Reference Answer','Student\\'s Answer','Obtained marks']\no_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T05:09:37.659108Z","iopub.execute_input":"2024-12-31T05:09:37.659352Z","iopub.status.idle":"2024-12-31T05:09:38.531366Z","shell.execute_reply.started":"2024-12-31T05:09:37.659331Z","shell.execute_reply":"2024-12-31T05:09:38.530619Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                           Questions  \\\n0  पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...   \n1  पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...   \n2  पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...   \n3  पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...   \n4  पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...   \n\n                                    Reference Answer  \\\n0  पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...   \n1  पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...   \n2  पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...   \n3  पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...   \n4  पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...   \n\n                                    Student's Answer  Obtained marks  \n0  पढाईले मानिसलाई केवल केही ज्ञान मात्र दिन्छ, त...             0.0  \n1  पढाईले मानिसलाई केही थाहा दिने गर्दछ, जसले जीव...             0.0  \n2  पढाई मानिसको सोच र जीवनशैलीमा ठूलो परिवर्तन ल्...             1.0  \n3  पढाई केवल ज्ञानको स्रोत हो, तर जीवनका समस्याहर...             0.0  \n4  पढाईले जीवनका केही पक्षहरूमा परिवर्तन ल्याउँछ।...             0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Questions</th>\n      <th>Reference Answer</th>\n      <th>Student's Answer</th>\n      <th>Obtained marks</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...</td>\n      <td>पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...</td>\n      <td>पढाईले मानिसलाई केवल केही ज्ञान मात्र दिन्छ, त...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...</td>\n      <td>पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...</td>\n      <td>पढाईले मानिसलाई केही थाहा दिने गर्दछ, जसले जीव...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...</td>\n      <td>पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...</td>\n      <td>पढाई मानिसको सोच र जीवनशैलीमा ठूलो परिवर्तन ल्...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...</td>\n      <td>पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...</td>\n      <td>पढाई केवल ज्ञानको स्रोत हो, तर जीवनका समस्याहर...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...</td>\n      <td>पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। य...</td>\n      <td>पढाईले जीवनका केही पक्षहरूमा परिवर्तन ल्याउँछ।...</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"data=pd.concat([p_data,o_data,a_data])\ndata = data[(data['Obtained marks'] == 0) | (data['Obtained marks'] == 2)]\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T05:09:38.532104Z","iopub.execute_input":"2024-12-31T05:09:38.532357Z","iopub.status.idle":"2024-12-31T05:09:38.545618Z","shell.execute_reply.started":"2024-12-31T05:09:38.532336Z","shell.execute_reply":"2024-12-31T05:09:38.544849Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                              Questions  \\\n6031  सहकारी संस्थाहरूले किसानलाई कसरी सहयोग गर्न सक...   \n6032  कृषिको विकासले नेपालको समग्र समृद्धिमा कस्तो य...   \n6037  कृषिको विकासले नेपालको समग्र समृद्धिमा कस्तो य...   \n6038   माउन्ट एभरेष्टको उचाइ के हो र यो कहाँ अवस्थित छ?   \n6041   माउन्ट एभरेष्टको उचाइ के हो र यो कहाँ अवस्थित छ?   \n\n                                       Reference Answer  \\\n6031   सहकारी संस्थाहरूले किसानलाई उत्पादनका लागि सस...   \n6032   कृषिको विकासले रोजगारीका अवसरहरू सिर्जना गर्छ...   \n6037   कृषिको विकासले रोजगारीका अवसरहरू सिर्जना गर्छ...   \n6038  माउन्ट एभरेष्टको उचाइ ८,८४८.८६ मीटर (२९,०३१.७ ...   \n6041  माउन्ट एभरेष्टको उचाइ ८,८४८.८६ मीटर (२९,०३१.७ ...   \n\n                                       Student's Answer  Obtained marks  \n6031                          सहकारीले सस्तो बीउ दिन्छ।             0.0  \n6032   कृषिको विकासले देशमा रोजगारी सिर्जना गर्न, उत...             2.0  \n6037                                खेती राम्रो बनाउँछ।             0.0  \n6038  माउन्ट एभरेष्टको उचाइ ८,८४८.८६ मीटर हो र यो ने...             2.0  \n6041  माउन्ट एभरेष्ट ८,८४८ मीटर उचो छ र यो नेपाल र च...             0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Questions</th>\n      <th>Reference Answer</th>\n      <th>Student's Answer</th>\n      <th>Obtained marks</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6031</th>\n      <td>सहकारी संस्थाहरूले किसानलाई कसरी सहयोग गर्न सक...</td>\n      <td>सहकारी संस्थाहरूले किसानलाई उत्पादनका लागि सस...</td>\n      <td>सहकारीले सस्तो बीउ दिन्छ।</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6032</th>\n      <td>कृषिको विकासले नेपालको समग्र समृद्धिमा कस्तो य...</td>\n      <td>कृषिको विकासले रोजगारीका अवसरहरू सिर्जना गर्छ...</td>\n      <td>कृषिको विकासले देशमा रोजगारी सिर्जना गर्न, उत...</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>6037</th>\n      <td>कृषिको विकासले नेपालको समग्र समृद्धिमा कस्तो य...</td>\n      <td>कृषिको विकासले रोजगारीका अवसरहरू सिर्जना गर्छ...</td>\n      <td>खेती राम्रो बनाउँछ।</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6038</th>\n      <td>माउन्ट एभरेष्टको उचाइ के हो र यो कहाँ अवस्थित छ?</td>\n      <td>माउन्ट एभरेष्टको उचाइ ८,८४८.८६ मीटर (२९,०३१.७ ...</td>\n      <td>माउन्ट एभरेष्टको उचाइ ८,८४८.८६ मीटर हो र यो ने...</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>6041</th>\n      <td>माउन्ट एभरेष्टको उचाइ के हो र यो कहाँ अवस्थित छ?</td>\n      <td>माउन्ट एभरेष्टको उचाइ ८,८४८.८६ मीटर (२९,०३१.७ ...</td>\n      <td>माउन्ट एभरेष्ट ८,८४८ मीटर उचो छ र यो नेपाल र च...</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"import seaborn as sns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T05:09:38.546546Z","iopub.execute_input":"2024-12-31T05:09:38.546758Z","iopub.status.idle":"2024-12-31T05:09:38.733002Z","shell.execute_reply.started":"2024-12-31T05:09:38.546735Z","shell.execute_reply":"2024-12-31T05:09:38.732163Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# eda","metadata":{}},{"cell_type":"code","source":"# from transformers import Trainer, TrainingArguments\n\n# from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModelForSequenceClassification\n\n# data['Questions'] = data['Questions'].astype(str)\n# data['Reference Answer'] = data['Reference Answer'].astype(str)\n# data[\"Student's Answer\"] = data[\"Student's Answer\"].astype(str)\n\n# # Combine columns for input_text\n# data['input_text'] = (\n#     # \"Question: \" + data['Questions'] +\n#     \" Reference Answer: \" + data['Reference Answer'] +\n#     \" Student Answer: \" + data[\"Student's Answer\"]\n# )\n\n# data['target'] = data['Obtained marks']\n\n# # Split data\n# train_texts, val_texts, train_labels, val_labels = train_test_split(\n#     data['input_text'], data['target'], test_size=0.2, random_state=42,stratify=data['target']\n# )\n\n# # Tokenize\n# tokenizer = AutoTokenizer.from_pretrained(\"NepBERTa/NepBERTa\")\n# train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=512)\n# val_encodings = tokenizer(list(val_texts), truncation=True, padding=True, max_length=512)\n\n\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AutoTokenizer\n\n# Preprocessing: Remove data with more than 512 tokens\ndef filter_long_texts(texts,labels, tokenizer, max_length=512):\n    # Tokenize texts and filter out those that exceed max_length\n    filtered_texts = []\n    filtered_labels = []\n    for text, label in zip(texts, labels):\n        tokenized = tokenizer(text, truncation=True, padding=False)\n        if len(tokenized['input_ids']) <= max_length:  # Check if tokenized text is within the limit\n            filtered_texts.append(text)\n            filtered_labels.append(label)\n    return filtered_texts, filtered_labels\n\n# Preprocess data\ndata['Questions'] = data['Questions'].astype(str)\ndata['Reference Answer'] = data['Reference Answer'].astype(str)\ndata[\"Student's Answer\"] = data[\"Student's Answer\"].astype(str)\n\n# Combine columns for input_text\ndata['input_text'] = (\n    \"Question: \" + data['Questions'] +\n    \"Reference Answer: \" + data['Reference Answer'] +\n    \" Student Answer: \" + data[\"Student's Answer\"]\n)\n\ndata['target'] = data['Obtained marks']\n\n# Split data\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    data['input_text'], data['target'], test_size=0.2, random_state=42, stratify=data['target']\n)\n\n# Initialize tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"NepBERTa/NepBERTa\")\n\n# Remove texts that exceed max_length (512 tokens)\ntrain_texts, train_labels = filter_long_texts(train_texts,train_labels, tokenizer, max_length=512)\nval_texts, val_labels = filter_long_texts(val_texts,val_labels, tokenizer, max_length=512)\n\n# Tokenize\ntrain_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=512)\nval_encodings = tokenizer(list(val_texts), truncation=True, padding=True, max_length=512)\n\n# Optionally, check how many texts were removed\nprint(f\"Removed {len(data['input_text']) - len(train_texts)} texts that exceeded 512 tokens.\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["4011a9b2fa5a4bd9873c48891361e5e3","1faffb0a2ab849d191efb6b65b0ea102","d88f48de82934ed7a4564ebeb2e870b1","fd729c3ba94e4327a12ab8d2e3de63ed","388e0307ac974c6787c55ab0e7a22fb0","42bae3bf886c4999ad9a20b8164e6159","fecc4b5e32d14f0499c181abe2e1641c","2ae66e2fbba241499f03ad2bd4828af8","b59570a3cfeb449db04045a31b1654e9","493c7173aaa049139cda553df4fcbfea","be9bc652b0bd40d5be8f9447aa013728","6e70245367734976b684c92bf39afe94","13e2f4461f2c4701b292bd102b2cbeb1","0178a299058a4610a3b845f1ae875ac1","c1e0a084b9564d33b9d29d159c29bd41","82789f34d99c4bf3bca16496c14f7331","6e4e77f1e00e478eb66f60a19d32fb66","8e84f2ea84d941a4b94edd728a7b89fc","ce24cd856647498eaa93b8b981ab0fbd","dec340546de549a58782d120fa8d536a","8f972664f79a4d5a8f95d55d241f03e4","74e38d925c2c43ef8327ad85ac0fcee3"]},"id":"apTVvzGRpzS3","outputId":"81fcd5a2-3b09-4272-a65c-7778ff571c60","trusted":true,"execution":{"iopub.status.busy":"2024-12-31T05:09:38.733864Z","iopub.execute_input":"2024-12-31T05:09:38.734368Z","iopub.status.idle":"2024-12-31T05:09:44.809430Z","shell.execute_reply.started":"2024-12-31T05:09:38.734336Z","shell.execute_reply":"2024-12-31T05:09:44.808599Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/652 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"239bc859877a4a37ab8a4cb1752062c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/547k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af3edf32bca64176b2b4969bbe03149a"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\nAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"name":"stdout","text":"Removed 1790 texts that exceeded 512 tokens.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ncounts=data['Obtained marks'].value_counts()\nprint(counts)\ncounts=counts/counts.sum()\nprint(counts)\nprint('on dataset')\nprint(train_encodings[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T05:09:44.810113Z","iopub.execute_input":"2024-12-31T05:09:44.810405Z","iopub.status.idle":"2024-12-31T05:09:44.823561Z","shell.execute_reply.started":"2024-12-31T05:09:44.810382Z","shell.execute_reply":"2024-12-31T05:09:44.822696Z"}},"outputs":[{"name":"stdout","text":"Obtained marks\n2.0    5340\n0.0    3606\nName: count, dtype: int64\nObtained marks\n2.0    0.596915\n0.0    0.403085\nName: count, dtype: float64\non dataset\nEncoding(num_tokens=415, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import torch\n\n# Dataset class for PyTorch\nclass NepaliExamDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n        return item\n\n# Create the dataset instances\ntrain_dataset = NepaliExamDataset(train_encodings, train_labels)\nval_dataset = NepaliExamDataset(val_encodings, val_labels)\n\n# Map labels to class indices\nlabel_mapping = {0: 0, 0.5: 1, 1: 1, 1.5: 2, 2: 2}\n\n# Apply label mapping to training and validation datasets\ntrain_dataset.labels = [label_mapping[label] for label in train_dataset.labels]\nval_dataset.labels = [label_mapping[label] for label in val_dataset.labels]\n","metadata":{"id":"pujtOpJfqQby","trusted":true,"execution":{"iopub.status.busy":"2024-12-31T05:09:44.824572Z","iopub.execute_input":"2024-12-31T05:09:44.824855Z","iopub.status.idle":"2024-12-31T05:09:44.839406Z","shell.execute_reply.started":"2024-12-31T05:09:44.824834Z","shell.execute_reply":"2024-12-31T05:09:44.838649Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"#distribution after spliting\nfrom collections import Counter\n\ntrain_labels = train_dataset.labels  \nlabel_counts = Counter(train_labels)  \n\ntest_labels = val_dataset.labels  \nlabel_counts_test = Counter(test_labels) \n\nprint(label_counts)\nprint(label_counts_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T05:09:44.840136Z","iopub.execute_input":"2024-12-31T05:09:44.840462Z","iopub.status.idle":"2024-12-31T05:09:44.861693Z","shell.execute_reply.started":"2024-12-31T05:09:44.840431Z","shell.execute_reply":"2024-12-31T05:09:44.861026Z"}},"outputs":[{"name":"stdout","text":"Counter({2: 4272, 0: 2884})\nCounter({2: 1068, 0: 722})\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"from huggingface_hub import login\n\n# Replace 'your_token_here' with your actual token\ntoken='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'\nlogin(token=token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T05:09:44.862410Z","iopub.execute_input":"2024-12-31T05:09:44.862643Z","iopub.status.idle":"2024-12-31T05:09:44.927944Z","shell.execute_reply.started":"2024-12-31T05:09:44.862617Z","shell.execute_reply":"2024-12-31T05:09:44.927315Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification,Trainer,TrainingArguments\ntokenizer = AutoTokenizer.from_pretrained(\"NepBERTa/NepBERTa\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"NepBERTa/NepBERTa\",from_tf=True,num_labels=3)\n\nmodel.config.problem_type = \"single_label_classification\"\n# Freeze the embeddings layer\nfor param in model.bert.embeddings.parameters():\n    param.requires_grad = False\n\n# Freeze the lower 6 encoder layers\nfor layer in model.bert.encoder.layer[:6]:\n    for param in layer.parameters():\n        param.requires_grad = False\n\n# Higher layers (7-12) remain trainable\nfor layer in model.bert.encoder.layer[6:]:\n    for param in layer.parameters():\n        param.requires_grad = True\n\n# Ensure the classifier layer is trainable\nfor param in model.classifier.parameters():\n    param.requires_grad = True\n\n# Check if the parameters are correctly frozen or trainable\nprint(model)","metadata":{"colab":{"background_save":true},"id":"MjQTijBWqetr","outputId":"0a6868c3-f00f-4e1d-9c99-c008dda4e938","trusted":true,"execution":{"iopub.status.busy":"2024-12-31T05:09:44.928618Z","iopub.execute_input":"2024-12-31T05:09:44.928819Z","iopub.status.idle":"2024-12-31T05:10:03.387167Z","shell.execute_reply.started":"2024-12-31T05:09:44.928793Z","shell.execute_reply":"2024-12-31T05:10:03.386356Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tf_model.h5:   0%|          | 0.00/534M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a520c13b6f74835aa3abd3c04995771"}},"metadata":{}},{"name":"stderr","text":"All TF 2.0 model weights were used when initializing BertForSequenceClassification.\n\nAll the weights of BertForSequenceClassification were initialized from the TF 2.0 model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=3, bias=True)\n)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import (\n    mean_squared_error, mean_absolute_error, r2_score, \n    accuracy_score, f1_score, confusion_matrix, \n    precision_score, recall_score\n)\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    # Convert logits to predicted class indices\n    predictions = np.argmax(logits, axis=-1)\n\n    # Compute classification metrics\n    accuracy = accuracy_score(labels, predictions)\n    f1 = f1_score(labels, predictions, average=\"weighted\")\n    precision = precision_score(labels, predictions, average=\"weighted\")\n    recall = recall_score(labels, predictions, average=\"weighted\")\n    mse = mean_squared_error(labels, predictions)\n    conf_matrix = confusion_matrix(labels, predictions)\n\n    # Print the confusion matrix\n    print(\"Confusion Matrix:\\n\", conf_matrix)\n\n    return {\n        \"accuracy\": accuracy,\n        \"f1\": f1,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"mse\": mse\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T05:10:03.388093Z","iopub.execute_input":"2024-12-31T05:10:03.388410Z","iopub.status.idle":"2024-12-31T05:10:03.393667Z","shell.execute_reply.started":"2024-12-31T05:10:03.388379Z","shell.execute_reply":"2024-12-31T05:10:03.392755Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# sample_text=data['Questions'][0]\n# sample_text = \"पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। यसबारे तपाईंको विचार दिनुहोस्।\"\n# tokenized=tokenizer.tokenize(sample_text)\n# ids=tokenizer.convert_tokens_to_ids(tokenized)\n\n# print(len(tokenized))\n# print(ids)\n# print(tokenizer.get_added_vocab())\n\n#train on following parameters for 4-4 epoch\n  # learning_rate:\n  #   values: [3e-4, 1e-4, 5e-5, 3e-5]\n  # per_gpu_train_batch_size:\n  #   values: [8, 16, 32, 64, 128]\n\n\n# Training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=1e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=30,\n    weight_decay=0.01,\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    save_total_limit=2\n)\n\n# Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T05:10:03.394393Z","iopub.execute_input":"2024-12-31T05:10:03.394612Z","iopub.status.idle":"2024-12-31T05:10:05.251680Z","shell.execute_reply.started":"2024-12-31T05:10:03.394593Z","shell.execute_reply":"2024-12-31T05:10:05.250789Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import wandb\nwandb.login(key='642cda66602a89962a6e329a891195bb114f74cf')\nwandb.init(project='1', name='all added 2')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T05:10:05.252688Z","iopub.execute_input":"2024-12-31T05:10:05.252936Z","iopub.status.idle":"2024-12-31T05:10:18.081803Z","shell.execute_reply.started":"2024-12-31T05:10:05.252913Z","shell.execute_reply":"2024-12-31T05:10:18.081117Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manidhsubedi821\u001b[0m (\u001b[33manidhsubedi821-wrc\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241231_051011-brqq1h7e</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/anidhsubedi821-wrc/1/runs/brqq1h7e' target=\"_blank\">all added 2</a></strong> to <a href='https://wandb.ai/anidhsubedi821-wrc/1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/anidhsubedi821-wrc/1' target=\"_blank\">https://wandb.ai/anidhsubedi821-wrc/1</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/anidhsubedi821-wrc/1/runs/brqq1h7e' target=\"_blank\">https://wandb.ai/anidhsubedi821-wrc/1/runs/brqq1h7e</a>"},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/anidhsubedi821-wrc/1/runs/brqq1h7e?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7cc5d87caaa0>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"# Train the model\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T05:10:18.082587Z","iopub.execute_input":"2024-12-31T05:10:18.082882Z","iopub.status.idle":"2024-12-31T07:23:57.847420Z","shell.execute_reply.started":"2024-12-31T05:10:18.082842Z","shell.execute_reply":"2024-12-31T07:23:57.846584Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='13440' max='13440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [13440/13440 2:13:36, Epoch 30/30]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Mse</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.471300</td>\n      <td>0.478305</td>\n      <td>0.778212</td>\n      <td>0.772069</td>\n      <td>0.779712</td>\n      <td>0.778212</td>\n      <td>0.887151</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.537600</td>\n      <td>0.403003</td>\n      <td>0.825140</td>\n      <td>0.818896</td>\n      <td>0.834543</td>\n      <td>0.825140</td>\n      <td>0.699441</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.322700</td>\n      <td>0.375598</td>\n      <td>0.848603</td>\n      <td>0.845860</td>\n      <td>0.850985</td>\n      <td>0.848603</td>\n      <td>0.605587</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.386000</td>\n      <td>0.447324</td>\n      <td>0.831285</td>\n      <td>0.823198</td>\n      <td>0.849530</td>\n      <td>0.831285</td>\n      <td>0.674860</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.250300</td>\n      <td>0.366058</td>\n      <td>0.866480</td>\n      <td>0.865898</td>\n      <td>0.866006</td>\n      <td>0.866480</td>\n      <td>0.534078</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.315200</td>\n      <td>0.418770</td>\n      <td>0.851955</td>\n      <td>0.852366</td>\n      <td>0.853171</td>\n      <td>0.851955</td>\n      <td>0.592179</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.259400</td>\n      <td>0.415987</td>\n      <td>0.852514</td>\n      <td>0.852087</td>\n      <td>0.851977</td>\n      <td>0.852514</td>\n      <td>0.589944</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.324100</td>\n      <td>0.429435</td>\n      <td>0.852514</td>\n      <td>0.853237</td>\n      <td>0.855413</td>\n      <td>0.852514</td>\n      <td>0.589944</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.137100</td>\n      <td>0.460591</td>\n      <td>0.850279</td>\n      <td>0.851223</td>\n      <td>0.854934</td>\n      <td>0.850279</td>\n      <td>0.598883</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.193900</td>\n      <td>0.442941</td>\n      <td>0.855866</td>\n      <td>0.854434</td>\n      <td>0.855933</td>\n      <td>0.855866</td>\n      <td>0.576536</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.267800</td>\n      <td>0.529615</td>\n      <td>0.846927</td>\n      <td>0.844934</td>\n      <td>0.847511</td>\n      <td>0.846927</td>\n      <td>0.612291</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.233900</td>\n      <td>0.523548</td>\n      <td>0.859218</td>\n      <td>0.858261</td>\n      <td>0.858825</td>\n      <td>0.859218</td>\n      <td>0.563128</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.135300</td>\n      <td>0.536828</td>\n      <td>0.852514</td>\n      <td>0.850698</td>\n      <td>0.853077</td>\n      <td>0.852514</td>\n      <td>0.589944</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.207400</td>\n      <td>0.699135</td>\n      <td>0.844693</td>\n      <td>0.841200</td>\n      <td>0.848749</td>\n      <td>0.844693</td>\n      <td>0.621229</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.232400</td>\n      <td>0.663036</td>\n      <td>0.849162</td>\n      <td>0.846338</td>\n      <td>0.851814</td>\n      <td>0.849162</td>\n      <td>0.603352</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.124300</td>\n      <td>0.630551</td>\n      <td>0.851397</td>\n      <td>0.849619</td>\n      <td>0.851832</td>\n      <td>0.851397</td>\n      <td>0.594413</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.232500</td>\n      <td>0.633451</td>\n      <td>0.855866</td>\n      <td>0.855056</td>\n      <td>0.855325</td>\n      <td>0.855866</td>\n      <td>0.576536</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.143500</td>\n      <td>0.716588</td>\n      <td>0.851955</td>\n      <td>0.850158</td>\n      <td>0.852453</td>\n      <td>0.851955</td>\n      <td>0.592179</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.050100</td>\n      <td>0.721996</td>\n      <td>0.851397</td>\n      <td>0.849772</td>\n      <td>0.851576</td>\n      <td>0.851397</td>\n      <td>0.594413</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.116000</td>\n      <td>0.714509</td>\n      <td>0.848603</td>\n      <td>0.847124</td>\n      <td>0.848465</td>\n      <td>0.848603</td>\n      <td>0.605587</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>0.073000</td>\n      <td>0.852827</td>\n      <td>0.846927</td>\n      <td>0.844000</td>\n      <td>0.849635</td>\n      <td>0.846927</td>\n      <td>0.612291</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>0.158800</td>\n      <td>0.712525</td>\n      <td>0.846927</td>\n      <td>0.846281</td>\n      <td>0.846269</td>\n      <td>0.846927</td>\n      <td>0.612291</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>0.171800</td>\n      <td>0.821558</td>\n      <td>0.839665</td>\n      <td>0.836433</td>\n      <td>0.842415</td>\n      <td>0.839665</td>\n      <td>0.641341</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>0.118400</td>\n      <td>0.779898</td>\n      <td>0.851955</td>\n      <td>0.850411</td>\n      <td>0.852035</td>\n      <td>0.851955</td>\n      <td>0.592179</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.101800</td>\n      <td>0.817025</td>\n      <td>0.850279</td>\n      <td>0.848938</td>\n      <td>0.850032</td>\n      <td>0.850279</td>\n      <td>0.598883</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>0.069700</td>\n      <td>0.850625</td>\n      <td>0.850279</td>\n      <td>0.848383</td>\n      <td>0.850870</td>\n      <td>0.850279</td>\n      <td>0.598883</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>0.120300</td>\n      <td>0.874059</td>\n      <td>0.849721</td>\n      <td>0.847683</td>\n      <td>0.850552</td>\n      <td>0.849721</td>\n      <td>0.601117</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>0.149200</td>\n      <td>0.863184</td>\n      <td>0.852514</td>\n      <td>0.850801</td>\n      <td>0.852892</td>\n      <td>0.852514</td>\n      <td>0.589944</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>0.163100</td>\n      <td>0.853789</td>\n      <td>0.855307</td>\n      <td>0.853846</td>\n      <td>0.855397</td>\n      <td>0.855307</td>\n      <td>0.578771</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.095900</td>\n      <td>0.860610</td>\n      <td>0.854749</td>\n      <td>0.853209</td>\n      <td>0.854937</td>\n      <td>0.854749</td>\n      <td>0.581006</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Confusion Matrix:\n [[443 279]\n [118 950]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[ 469  253]\n [  60 1008]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[528 194]\n [ 77 991]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[ 453  269]\n [  33 1035]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[585 137]\n [102 966]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[603 119]\n [146 922]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[578 144]\n [120 948]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[616 106]\n [158 910]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[624  98]\n [170 898]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[557 165]\n [ 93 975]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[540 182]\n [ 92 976]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[570 152]\n [100 968]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[547 175]\n [ 89 979]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[514 208]\n [ 70 998]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[527 195]\n [ 75 993]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[547 175]\n [ 91 977]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[571 151]\n [107 961]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[547 175]\n [ 90 978]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[550 172]\n [ 94 974]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[551 171]\n [100 968]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[524 198]\n [ 76 992]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[568 154]\n [120 948]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[515 207]\n [ 80 988]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[552 170]\n [ 95 973]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[555 167]\n [101 967]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[544 178]\n [ 90 978]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[541 181]\n [ 88 980]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[549 173]\n [ 91 977]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[556 166]\n [ 93 975]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n [[554 168]\n [ 92 976]]\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=13440, training_loss=0.1967967118735292, metrics={'train_runtime': 8018.3952, 'train_samples_per_second': 26.773, 'train_steps_per_second': 1.676, 'total_flos': 4.57838930369268e+16, 'train_loss': 0.1967967118735292, 'epoch': 30.0})"},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"# for the manual evaluation","metadata":{"id":"-cRTtMzNqkfT","execution":{"execution_failed":"2024-12-28T08:57:58.464Z"}}},{"cell_type":"markdown","source":"# ","metadata":{}},{"cell_type":"code","source":"question=\"\"\nreference_text = \"पढाईले मानिसको जीवनमा ठूलो परिवर्तन ल्याउँछ। यसबारे तपाईंको विचार दिनुहोस्।\"\nstudent_text = \"पढाईले मानिसको जीवनलाई सकारात्मक बनाउँछ। यसबारे तपाईंको धारणा के हो?\"\ninputs =  ( \"Question: \" + question+\n    \" Reference Answer: \" + reference_text+\n    \" Student Answer: \" + reference_text[:5])\n\n\nmodel=model.to(device='cpu')\ninputs = tokenizer(\n    inputs,\n    return_tensors=\"pt\",\n    padding=True,\n    truncation=True,\n    max_length=512\n)\n\n# Perform inference\nmodel.eval()\nwith torch.no_grad():\n    outputs = model(**inputs)\n    logits = outputs.logits\n    predicted_grade = torch.argmax(logits, dim=-1).item()\n    print(predicted_grade)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T07:23:57.849938Z","iopub.execute_input":"2024-12-31T07:23:57.850141Z","iopub.status.idle":"2024-12-31T07:23:58.314822Z","shell.execute_reply.started":"2024-12-31T07:23:57.850122Z","shell.execute_reply":"2024-12-31T07:23:58.314108Z"}},"outputs":[{"name":"stdout","text":"0\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}